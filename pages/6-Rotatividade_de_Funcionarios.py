import streamlit as st
import pandas as pd
import plotly.express as px
import joblib
from pathlib import Path
from utils.ui import setup_sidebar, add_back_to_top
from utils.visualizations import plot_confusion_matrix

st.set_page_config(page_title="Previsor de Rotatividade", page_icon="üë§", layout="wide")

setup_sidebar()
add_back_to_top()

st.title("üë§ Previsor de Rotatividade de Funcion√°rios")

MODEL_DIR = Path("./data/model")

tabs = st.tabs(["Vis√£o Geral", "Previs√£o", "M√©tricas do modelo", "Feature Importance"])


with tabs[0]:
    st.subheader("Enunciado do Projeto")
    st.markdown(
        """
    No din√¢mico ambiente empresarial atual, a reten√ß√£o de talentos tornou-se um fator cr√≠tico para o sucesso sustent√°vel das organiza√ß√µes.
    Este projeto concentra-se na an√°lise dos dados de recursos humanos de uma empresa com o objetivo de desenvolver um modelo de machine learning supervisionado
    para prever com precis√£o se um funcion√°rio est√° propenso a deixar a organiza√ß√£o.

    A aplica√ß√£o de t√©cnicas avan√ßadas de machine learning na supervis√£o de recursos humanos representa uma oportunidade √∫nica para otimizar a tomada de decis√µes
    baseada em dados e melhorar a efici√™ncia operacional no √¢mbito da gest√£o de talentos.
    """
    )

    st.subheader("Objetivo")
    st.markdown(
        """
    Desenvolver um modelo de machine learning supervisionado capaz de prever a probabilidade de um funcion√°rio deixar a empresa, utilizando dados hist√≥ricos do departamento de Recursos Humanos.
    O modelo busca identificar padr√µes e fatores que influenciam a rotatividade para apoiar a√ß√µes preventivas de reten√ß√£o.
    """
    )

    st.subheader("Resultados e Conclus√µes")
    st.markdown(
        """
    O projeto alcan√ßou com sucesso o objetivo de desenvolver um modelo preditivo.
    - **An√°lise Explorat√≥ria**: Verificou-se que a rotatividade est√° associada a fatores como idade (mais jovens saem mais), menor tempo de casa, menor sal√°rio e menor experi√™ncia total.
    - **Modelagem**: O algoritmo **XGBoost** foi o destaque, alcan√ßando **99.6% de acur√°cia** nos dados de teste, superando Random Forest e Regress√£o Log√≠stica.
    - **Fatores Cr√≠ticos**: As vari√°veis mais influentes detectadas pelo modelo foram:
        - `MaritalStatus`: Solteiros tendem a ter maior rotatividade.
        - `TotalWorkingYears` e `YearsAtCompany`: Menor tempo de casa/experi√™ncia aumenta o risco.
        - `Age`: Jovens s√£o mais propensos a sair.

    O modelo fornece insights estrat√©gicos para o RH antecipar desligamentos e planejar a√ß√µes de reten√ß√£o focadas.
    """
    )


with tabs[1]:
    main_column1, spacer, main_column2 = st.columns([3, 0.2, 1])

    with main_column1:
        st.subheader("Par√¢metros de Entrada")

        col1, spacer_inner, col2, spacer_inner2, col3 = st.columns([1, 0.1, 1, 0.1, 1])

        with col1:
            st.markdown("##### Dados Temporais")
            age = st.slider("Idade", 18, 60, 30)
            total_years = st.slider("Anos totais de experi√™ncia", 0, 30, 10)
            years_at_company = st.slider("Anos na empresa atual", 0, 20, 5)
            years_with_manager = st.slider("Anos com o mesmo gerente", 0, 10, 3)

        with col2:
            st.markdown("##### Dados Pessoais")
            marital = st.pills(
                "Estado civil", ["Single", "Married", "Divorced"], default="Single"
            )
            gender = st.pills("G√™nero", ["Male", "Female"], default="Male")
            travel = st.selectbox(
                "Frequ√™ncia de viagens",
                ["Non-Travel", "Travel_Rarely", "Travel_Frequently"],
                index=1,
            )
            distance = st.slider("Dist√¢ncia da casa (km)", 0, 50, 10)

        with col3:
            st.markdown("##### Dados Profissionais")
            department = st.selectbox(
                "Departamento",
                ["Sales", "Research & Development", "Human Resources"],
                index=0,
            )
            job_role = st.selectbox(
                "Cargo",
                [
                    "Sales Executive",
                    "Research Scientist",
                    "Laboratory Technician",
                    "Manufacturing Director",
                    "Healthcare Representative",
                    "Manager",
                    "Sales Representative",
                    "Research Director",
                    "Human Resources",
                ],
            )

        # Montagem do DataFrame de entrada
        input_data = pd.DataFrame(
            {
                "Age": [age],
                "TotalWorkingYears": [total_years],
                "YearsAtCompany": [years_at_company],
                "YearsWithCurrManager": [years_with_manager],
                "MaritalStatus": [marital],
                "BusinessTravel": [travel],
                "Department": [department],
                "Gender": [gender],
                "JobRole": [job_role],
                "DistanceFromHome": [distance],
                "Attrition": ["No"],
            }
        )

        # Engenharia de Features (Feature Engineering) b√°sica igual ao treinamento
        bins = [18, 25, 35, 45, 55, 65]
        labels = ["18-25", "26-35", "36-45", "46-55", "56+"]
        input_data["AgeGroup"] = pd.cut(
            input_data["Age"], bins=bins, labels=labels, right=False
        )
        input_data["FarFromHome"] = (input_data["DistanceFromHome"] > 10).astype(int)
        input_data["CompanyExperienceRatio"] = input_data["YearsAtCompany"] / (
            input_data["TotalWorkingYears"] + 1
        )
        input_data["AvgYearsPerCompany"] = input_data["TotalWorkingYears"] / (
            input_data["YearsAtCompany"] + 1
        )
        input_data["SalaryHikePerIncome"] = 0  # Placeholder se necess√°rio pelo modelo

        input_data_model = input_data.copy()

        # Carregamento dos objetos do modelo
        try:
            encoders = joblib.load(MODEL_DIR / "label_encoders.pkl")
            scaler = joblib.load(MODEL_DIR / "scaler.pkl")
            num_cols = joblib.load(MODEL_DIR / "num_cols.pkl")
            xgb_model = joblib.load(MODEL_DIR / "xgb_model.pkl")

            # Aplica√ß√£o dos Encoders
            categorical_cols = input_data_model.select_dtypes(
                include=["object", "category"]
            ).columns
            for col in categorical_cols:
                if col in encoders:
                    try:
                        input_data_model[col] = encoders[col].transform(
                            input_data_model[col]
                        )
                    except ValueError:
                        # Caso valor novo n√£o visto no treino
                        input_data_model[col] = 0

            # Aplica√ß√£o do Scaler
            # Filtrar colunas num√©ricas que realmente existem no input e no scaler
            numeric_cols_to_scale = [
                col for col in num_cols if col in input_data_model.columns
            ]
            if numeric_cols_to_scale:
                input_data_model[numeric_cols_to_scale] = scaler.transform(
                    input_data_model[numeric_cols_to_scale]
                )

        except FileNotFoundError as e:
            st.error(
                f"‚ùå Erro ao carregar arquivos do modelo. Verifique se a pasta `predictionHumanResources/data/model` existe e cont√™m os arquivos .pkl.\nDetalhe: {e}"
            )
            st.stop()
        except Exception as e:
            st.error(f"‚ùå Erro inesperado ao processar dados: {e}")
            st.stop()

    with main_column2:
        with st.container(border=True):
            st.subheader("Previs√£o")
            try:
                # Garantir colunas na ordem correta do modelo
                if hasattr(xgb_model, "feature_names_in_"):
                    for col in xgb_model.feature_names_in_:
                        if col not in input_data_model.columns:
                            input_data_model[col] = 0
                    input_data_model = input_data_model[xgb_model.feature_names_in_]

                # Predi√ß√£o
                prob = xgb_model.predict_proba(input_data_model)[0][1]

                if prob > 0.7:
                    delta_color = "inverse"
                    delta_text = "Alto Risco"
                    st.error(
                        "‚ö†Ô∏è **Aten√ß√£o:** Alta probabilidade de rotatividade! A√ß√µes preventivas s√£o fortemente recomendadas."
                    )
                elif prob > 0.4:
                    delta_color = "off"
                    delta_text = "Risco Moderado"
                    st.warning(
                        "‚ö†Ô∏è **Alerta:** Risco moderado de rotatividade. Vale a pena revisar os planos de desenvolvimento e engajamento."
                    )
                else:
                    delta_color = "normal"
                    delta_text = "Baixo Risco"
                    st.success(
                        "‚úÖ **Est√°vel:** Baixo risco de sa√≠da. O funcion√°rio demonstra boa estabilidade."
                    )

                st.metric(
                    label="Probabilidade de Sa√≠da",
                    value=f"{prob*100:.1f}%",
                    delta=delta_text,
                    delta_color=delta_color,
                )

            except Exception as e:
                st.error(f"‚ùå Erro ao fazer previs√£o: {e}")
                st.exception(e)


with tabs[2]:
    st.subheader("M√©tricas do modelo")
    try:
        metrics = joblib.load(MODEL_DIR / "model_metrics.pkl")
        conf_matrix = joblib.load(MODEL_DIR / "confusion_matrix.pkl")

        col_m1, col_m2, col_m3, col_m4, col_m5 = st.columns(5)
        col_m1.metric(
            "üéØ Acur√°cia",
            f"{metrics.get('Acur√°cia', 0):.2%}",
            help="Propor√ß√£o de acertos totais",
        )
        col_m2.metric(
            "üîç Precis√£o",
            f"{metrics.get('Precis√£o', 0):.2%}",
            help="Dos preditos como sa√≠da, quantos realmente sa√≠ram",
        )
        col_m3.metric(
            "üì° Recall",
            f"{metrics.get('Recall', 0):.2%}",
            help="Dos que realmente sa√≠ram, quantos o modelo achou",
        )
        col_m4.metric(
            "‚öñÔ∏è F1-Score",
            f"{metrics.get('F1-Score', 0):.2%}",
            help="M√©dia harm√¥nica entre Precis√£o e Recall",
        )
        auc_val = metrics.get("AUC-ROC")
        col_m5.metric("üìà AUC-ROC", f"{auc_val:.2%}" if auc_val else "N/A")

        col_conf1, col_conf2 = st.columns([1.5, 1])

        with col_conf1:
            plot_confusion_matrix(
                conf_matrix,
                x_labels=["N√£o Sai (0)", "Sai (1)"],
                y_labels=["N√£o Sai (0)", "Sai (1)"],
            )

        with col_conf2:
            tn, fp, fn, tp = conf_matrix.ravel()
            st.markdown("##### Matriz de Confus√£o")
            st.markdown(
                f"""
            **Legenda:**
            - **VN ({tn})**: Verdadeiros Negativos (Ficou e previsto Ficar)
            - **FP ({fp})**: Falsos Positivos (Ficou mas previsto Sair)
            - **FN ({fn})**: Falsos Negativos (Saiu mas previsto Ficar)
            - **VP ({tp})**: Verdadeiros Positivos (Saiu e previsto Sair)
            """
            )

    except FileNotFoundError:
        st.info(
            "Arquivos de m√©tricas n√£o encontrados. Execute o notebook de treino para ger√°-los."
        )
    except Exception as e:
        st.error(f"Erro ao carregar m√©tricas: {e}")


with tabs[3]:
    st.subheader("Import√¢ncia das Vari√°veis")

    try:
        feature_importance = (
            pd.DataFrame(
                {
                    "Feature": xgb_model.feature_names_in_,
                    "Import√¢ncia": xgb_model.feature_importances_,
                }
            )
            .sort_values("Import√¢ncia", ascending=False)
            .head(15)
        )

        feature_importance["Import√¢ncia (%)"] = (
            feature_importance["Import√¢ncia"]
            / feature_importance["Import√¢ncia"].sum()
            * 100
        ).round(2)

        col_fi1, col_fi2 = st.columns([2, 1])

        fig = px.bar(
            feature_importance.sort_values("Import√¢ncia (%)", ascending=True),
            x="Import√¢ncia (%)",
            y="Feature",
            orientation="h",
            text="Import√¢ncia (%)",
            title="<b>Top 15 Vari√°veis Mais Importantes</b>",
            labels={
                "Import√¢ncia (%)": "Import√¢ncia Relativa (%)",
                "Feature": "Vari√°vel",
            },
            color_discrete_sequence=["#1f77b4"],
            template="plotly_white",
        )

        fig.update_traces(
            texttemplate="%{text:.1f}%",
            textposition="outside",
            hovertemplate="<b>%{y}</b><br>Import√¢ncia: %{x:.2f}%<extra></extra>",
        )

        fig.update_layout(
            yaxis={"categoryorder": "total ascending"},
            xaxis=dict(showgrid=True, gridcolor="lightgray"),
            showlegend=False,
            margin=dict(l=0, r=0, t=40, b=0),
            height=500,
        )

        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Erro ao gerar gr√°fico de import√¢ncia: {e}")
