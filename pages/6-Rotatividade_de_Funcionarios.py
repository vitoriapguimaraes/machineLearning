import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from pathlib import Path
from utils.ui import setup_sidebar, add_back_to_top

st.set_page_config(page_title="Previsor de Rotatividade", page_icon="üë§", layout="wide")

setup_sidebar()
add_back_to_top()

st.title("üë§ Previsor de Rotatividade de Funcion√°rios")
st.markdown(
    """
    Este aplicativo usa **Machine Learning (XGBoost)** para prever a probabilidade de um funcion√°rio deixar a empresa.
    """
)

MODEL_DIR = Path("./data/model")

tabs = st.tabs(["Previs√£o", "M√©tricas do modelo", "Feature Importance"])

with tabs[0]:
    main_column1, spacer, main_column2 = st.columns([3, 0.2, 1])

    with main_column1:
        st.subheader("‚öôÔ∏è Par√¢metros de Entrada")
        st.info("Altere os dados abaixo para obter a previs√£o.")

        col1, spacer_inner, col2, spacer_inner2, col3 = st.columns([1, 0.1, 1, 0.1, 1])

        with col1:
            st.markdown("##### üìÖ Dados Temporais")
            age = st.slider("Idade", 18, 60, 30)
            total_years = st.slider("Anos totais de experi√™ncia", 0, 30, 10)
            years_at_company = st.slider("Anos na empresa atual", 0, 20, 5)
            years_with_manager = st.slider("Anos com o mesmo gerente", 0, 10, 3)

        with col2:
            st.markdown("##### üë§ Dados Pessoais")
            marital = st.pills(
                "Estado civil", ["Single", "Married", "Divorced"], default="Single"
            )
            gender = st.pills("G√™nero", ["Male", "Female"], default="Male")
            travel = st.selectbox(
                "Frequ√™ncia de viagens",
                ["Non-Travel", "Travel_Rarely", "Travel_Frequently"],
                index=1,
            )
            distance = st.slider("Dist√¢ncia da casa (km)", 0, 50, 10)

        with col3:
            st.markdown("##### üíº Dados Profissionais")
            department = st.selectbox(
                "Departamento",
                ["Sales", "Research & Development", "Human Resources"],
                index=0,
            )
            job_role = st.selectbox(
                "Cargo",
                [
                    "Sales Executive",
                    "Research Scientist",
                    "Laboratory Technician",
                    "Manufacturing Director",
                    "Healthcare Representative",
                    "Manager",
                    "Sales Representative",
                    "Research Director",
                    "Human Resources",
                ],
            )

        # Montagem do DataFrame de entrada
        input_data = pd.DataFrame(
            {
                "Age": [age],
                "TotalWorkingYears": [total_years],
                "YearsAtCompany": [years_at_company],
                "YearsWithCurrManager": [years_with_manager],
                "MaritalStatus": [marital],
                "BusinessTravel": [travel],
                "Department": [department],
                "Gender": [gender],
                "JobRole": [job_role],
                "DistanceFromHome": [distance],
                "Attrition": [
                    "No"
                ],  # Placeholder column required for pipeline consistency
            }
        )

        # Engenharia de Features (Feature Engineering) b√°sica igual ao treinamento
        bins = [18, 25, 35, 45, 55, 65]
        labels = ["18-25", "26-35", "36-45", "46-55", "56+"]
        input_data["AgeGroup"] = pd.cut(
            input_data["Age"], bins=bins, labels=labels, right=False
        )
        input_data["FarFromHome"] = (input_data["DistanceFromHome"] > 10).astype(int)
        input_data["CompanyExperienceRatio"] = input_data["YearsAtCompany"] / (
            input_data["TotalWorkingYears"] + 1
        )
        input_data["AvgYearsPerCompany"] = input_data["TotalWorkingYears"] / (
            input_data["YearsAtCompany"] + 1
        )
        input_data["SalaryHikePerIncome"] = 0  # Placeholder se necess√°rio pelo modelo

        input_data_model = input_data.copy()

        # Carregamento dos objetos do modelo
        try:
            encoders = joblib.load(MODEL_DIR / "label_encoders.pkl")
            scaler = joblib.load(MODEL_DIR / "scaler.pkl")
            num_cols = joblib.load(MODEL_DIR / "num_cols.pkl")
            xgb_model = joblib.load(MODEL_DIR / "xgb_model.pkl")

            # Aplica√ß√£o dos Encoders
            categorical_cols = input_data_model.select_dtypes(
                include=["object", "category"]
            ).columns
            for col in categorical_cols:
                if col in encoders:
                    try:
                        input_data_model[col] = encoders[col].transform(
                            input_data_model[col]
                        )
                    except ValueError:
                        # Caso valor novo n√£o visto no treino
                        input_data_model[col] = 0

            # Aplica√ß√£o do Scaler
            # Filtrar colunas num√©ricas que realmente existem no input e no scaler
            numeric_cols_to_scale = [
                col for col in num_cols if col in input_data_model.columns
            ]
            if numeric_cols_to_scale:
                input_data_model[numeric_cols_to_scale] = scaler.transform(
                    input_data_model[numeric_cols_to_scale]
                )

        except FileNotFoundError as e:
            st.error(
                f"‚ùå Erro ao carregar arquivos do modelo. Verifique se a pasta `predictionHumanResources/data/model` existe e cont√™m os arquivos .pkl.\nDetalhe: {e}"
            )
            st.stop()
        except Exception as e:
            st.error(f"‚ùå Erro inesperado ao processar dados: {e}")
            st.stop()

    with main_column2:
        st.subheader("üîÆ Previs√£o")
        try:
            # Garantir colunas na ordem correta do modelo
            if hasattr(xgb_model, "feature_names_in_"):
                for col in xgb_model.feature_names_in_:
                    if col not in input_data_model.columns:
                        input_data_model[col] = 0
                input_data_model = input_data_model[xgb_model.feature_names_in_]

            # Predi√ß√£o
            prob = xgb_model.predict_proba(input_data_model)[0][1]

            if prob > 0.7:
                delta_color = "inverse"
                delta_text = "Alto Risco"
                st.error(
                    "‚ö†Ô∏è **Aten√ß√£o:** Alta probabilidade de rotatividade! A√ß√µes preventivas s√£o fortemente recomendadas."
                )
            elif prob > 0.4:
                delta_color = "off"
                delta_text = "Risco Moderado"
                st.warning(
                    "‚ö†Ô∏è **Alerta:** Risco moderado de rotatividade. Vale a pena revisar os planos de desenvolvimento e engajamento."
                )
            else:
                delta_color = "normal"
                delta_text = "Baixo Risco"
                st.success(
                    "‚úÖ **Est√°vel:** Baixo risco de sa√≠da. O funcion√°rio demonstra boa estabilidade."
                )

            st.metric(
                label="Probabilidade de Sa√≠da",
                value=f"{prob*100:.1f}%",
                delta=delta_text,
                delta_color=delta_color,
            )

        except Exception as e:
            st.error(f"‚ùå Erro ao fazer previs√£o: {e}")
            st.exception(e)


with tabs[1]:
    st.subheader("‚ÑπÔ∏è M√©tricas do modelo (Dados de Teste)")
    try:
        metrics = joblib.load(MODEL_DIR / "model_metrics.pkl")
        conf_matrix = joblib.load(MODEL_DIR / "confusion_matrix.pkl")

        col_m1, col_m2, col_m3, col_m4, col_m5 = st.columns(5)
        col_m1.metric(
            "üéØ Acur√°cia",
            f"{metrics.get('Acur√°cia', 0):.2%}",
            help="Propor√ß√£o de acertos totais",
        )
        col_m2.metric(
            "üîç Precis√£o",
            f"{metrics.get('Precis√£o', 0):.2%}",
            help="Dos preditos como sa√≠da, quantos realmente sa√≠ram",
        )
        col_m3.metric(
            "üì° Recall",
            f"{metrics.get('Recall', 0):.2%}",
            help="Dos que realmente sa√≠ram, quantos o modelo achou",
        )
        col_m4.metric(
            "‚öñÔ∏è F1-Score",
            f"{metrics.get('F1-Score', 0):.2%}",
            help="M√©dia harm√¥nica entre Precis√£o e Recall",
        )
        auc_val = metrics.get("AUC-ROC")
        col_m5.metric("üìà AUC-ROC", f"{auc_val:.2%}" if auc_val else "N/A")

        st.divider()
        st.subheader("üé≤ Matriz de Confus√£o")

        col_conf1, col_conf2 = st.columns([1.5, 1])

        with col_conf1:
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.heatmap(
                conf_matrix,
                annot=True,
                fmt="d",
                cmap="Blues",
                linewidths=2,
                linecolor="white",
                square=True,
                ax=ax,
                annot_kws={"size": 14, "weight": "bold"},
            )
            ax.set_xlabel("Predi√ß√£o", fontsize=10, fontweight="bold")
            ax.set_ylabel("Real", fontsize=10, fontweight="bold")
            ax.set_xticklabels(["N√£o Sai", "Sai"], fontsize=10)
            ax.set_yticklabels(["N√£o Sai", "Sai"], fontsize=10, rotation=0)
            st.pyplot(fig, use_container_width=False)

        with col_conf2:
            tn, fp, fn, tp = conf_matrix.ravel()
            st.markdown(
                f"""
            **Legenda:**
            - **VN ({tn})**: Verdadeiros Negativos (Ficou e previsto Ficar)
            - **FP ({fp})**: Falsos Positivos (Ficou mas previsto Sair)
            - **FN ({fn})**: Falsos Negativos (Saiu mas previsto Ficar)
            - **VP ({tp})**: Verdadeiros Positivos (Saiu e previsto Sair)
            """
            )

    except FileNotFoundError:
        st.info(
            "Arquivos de m√©tricas n√£o encontrados. Execute o notebook de treino para ger√°-los."
        )
    except Exception as e:
        st.error(f"Erro ao carregar m√©tricas: {e}")


with tabs[2]:
    st.subheader("üî¨ Import√¢ncia das Vari√°veis (Feature Importance)")
    st.markdown("Fatores que mais influenciam a decis√£o do modelo.")

    try:
        # Extrair import√¢ncias
        feature_importance = (
            pd.DataFrame(
                {
                    "Feature": xgb_model.feature_names_in_,
                    "Import√¢ncia": xgb_model.feature_importances_,
                }
            )
            .sort_values("Import√¢ncia", ascending=False)
            .head(15)
        )

        feature_importance["Import√¢ncia (%)"] = (
            feature_importance["Import√¢ncia"]
            / feature_importance["Import√¢ncia"].sum()
            * 100
        ).round(2)

        col_fi1, col_fi2 = st.columns([2, 1])

        with col_fi1:
            # Gr√°fico de Barras com R√≥tulos de Dados (Feedback request)
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.barh(
                feature_importance["Feature"],
                feature_importance["Import√¢ncia (%)"],
                color="#1f77b4",
                edgecolor="#0d47a1",
                alpha=0.8,
            )

            # Adicionando R√≥tulos de Dados (Data Labels)
            for bar in bars:
                width = bar.get_width()
                label_y_pos = bar.get_y() + bar.get_height() / 2
                ax.text(
                    width + 0.5,
                    label_y_pos,
                    f"{width:.1f}%",
                    va="center",
                    fontsize=9,
                    color="black",
                )

            ax.set_xlabel("Import√¢ncia (%)")
            ax.set_title("Top 15 Vari√°veis Mais Importantes")
            ax.invert_yaxis()  # Maior import√¢ncia no topo
            ax.grid(axis="x", linestyle="--", alpha=0.5)

            # Remover bordas desnecess√°rias
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)

            st.pyplot(fig, use_container_width=True)

        with col_fi2:
            st.dataframe(
                feature_importance[["Feature", "Import√¢ncia (%)"]].reset_index(
                    drop=True
                ),
                use_container_width=True,
                height=400,
            )

    except Exception as e:
        st.error(f"Erro ao gerar gr√°fico de import√¢ncia: {e}")
